{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dF3_pWNctyMT",
        "outputId": "00d30250-3679-4ebc-bab6-bc8e38cae82d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.00</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.00</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass                                      Name  \\\n",
              "886          887         0       2                     Montvila, Rev. Juozas   \n",
              "887          888         1       1              Graham, Miss. Margaret Edith   \n",
              "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
              "889          890         1       1                     Behr, Mr. Karl Howell   \n",
              "890          891         0       3                       Dooley, Mr. Patrick   \n",
              "\n",
              "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
              "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
              "887  female  19.0      0      0      112053  30.00   B42        S  \n",
              "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
              "889    male  26.0      0      0      111369  30.00  C148        C  \n",
              "890    male  32.0      0      0      370376   7.75   NaN        Q  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "titanic_data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "titanic_data.tail()\n",
        "#titanic_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vsZ97OfJt95g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "X = titanic_data[features]\n",
        "y = titanic_data[target]\n",
        "\n",
        "# Handle missing values and encode categorical variables\n",
        "numerical_features = ['Age', 'Fare']\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.          1.2322632  -0.07868358 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -0.50048197 -0.37714494 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.          0.1926161  -0.47486697 ...  0.          0.\n",
            "   1.        ]\n",
            " ...\n",
            " [ 1.          0.88571416 -0.35580399 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -1.19358003  1.68320121 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -0.65450376  0.86074761 ...  0.          0.\n",
            "   1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m7hBGEdPuLY_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize parameters\n",
        "n_features = X_train.shape[1]\n",
        "theta = np.zeros(n_features + 1)  # +1 for the intercept term\n",
        "\n",
        "# Add intercept term to X\n",
        "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test = np.c_[np.ones(X_test.shape[0]), X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.          1.2322632  -0.07868358 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -0.50048197 -0.37714494 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.          0.1926161  -0.47486697 ...  0.          0.\n",
            "   1.        ]\n",
            " ...\n",
            " [ 1.          0.88571416 -0.35580399 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -1.19358003  1.68320121 ...  0.          0.\n",
            "   1.        ]\n",
            " [ 1.         -0.65450376  0.86074761 ...  0.          0.\n",
            "   1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x89IguuUuQBM"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "    epsilon = 1e-5  # Small constant to prevent division by zero\n",
        "    cost = -1/m * (y.dot(np.log(h + epsilon)) + (1 - y).dot(np.log(1 - h + epsilon)))\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CDw-h9gtuT30"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, y, theta, learning_rate, num_iterations):\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(num_iterations)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        h = sigmoid(X.dot(theta))\n",
        "        gradients = X.T.dot(h - y) / m\n",
        "        theta = theta - learning_rate * gradients\n",
        "        cost_history[i] = compute_cost(X, y, theta)\n",
        "\n",
        "    return theta, cost_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cost_history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcost_history\u001b[49m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cost_history' is not defined"
          ]
        }
      ],
      "source": [
        "print(cost_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX7AZ-4auXm2",
        "outputId": "9e12ecf5-2457-473d-b6f0-de431c6cf312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal parameters: [-0.07090459 -0.15433616  0.32720924  0.23157942  0.14376593 -0.44624993\n",
            "  0.68985525 -0.76075984  0.11954125 -0.00230822 -0.18813762]\n",
            "Cost history over iterations: [0.69197511 0.69083386 0.68970332 0.68858335 0.68747383 0.68637464\n",
            " 0.68528566 0.68420677 0.68313786 0.68207879 0.68102947 0.67998977\n",
            " 0.67895959 0.6779388  0.67692731 0.675925   0.67493176 0.67394749\n",
            " 0.67297208 0.67200543 0.67104744 0.670098   0.66915702 0.66822439\n",
            " 0.66730002 0.66638382 0.66547568 0.66457551 0.66368321 0.66279871\n",
            " 0.6619219  0.66105269 0.660191   0.65933674 0.65848983 0.65765017\n",
            " 0.65681768 0.65599228 0.65517389 0.65436242 0.6535578  0.65275994\n",
            " 0.65196877 0.65118421 0.65040618 0.64963461 0.64886942 0.64811054\n",
            " 0.64735789 0.64661141 0.64587103 0.64513667 0.64440826 0.64368574\n",
            " 0.64296903 0.64225808 0.64155281 0.64085317 0.64015908 0.63947048\n",
            " 0.63878732 0.63810952 0.63743703 0.63676979 0.63610774 0.63545082\n",
            " 0.63479897 0.63415213 0.63351025 0.63287328 0.63224115 0.63161381\n",
            " 0.63099122 0.63037331 0.62976003 0.62915133 0.62854717 0.62794748\n",
            " 0.62735223 0.62676136 0.62617482 0.62559256 0.62501455 0.62444072\n",
            " 0.62387104 0.62330546 0.62274394 0.62218642 0.62163287 0.62108324\n",
            " 0.6205375  0.61999559 0.61945748 0.61892312 0.61839248 0.61786552\n",
            " 0.61734219 0.61682245 0.61630628 0.61579362 0.61528445 0.61477871\n",
            " 0.61427639 0.61377744 0.61328183 0.61278951 0.61230047 0.61181465\n",
            " 0.61133203 0.61085258 0.61037625 0.60990303 0.60943287 0.60896574\n",
            " 0.60850162 0.60804047 0.60758225 0.60712695 0.60667453 0.60622496\n",
            " 0.60577821 0.60533425 0.60489306 0.6044546  0.60401885 0.60358578\n",
            " 0.60315537 0.60272758 0.60230239 0.60187978 0.60145971 0.60104217\n",
            " 0.60062712 0.60021455 0.59980442 0.59939672 0.59899142 0.5985885\n",
            " 0.59818793 0.59778969 0.59739376 0.59700011 0.59660872 0.59621958\n",
            " 0.59583265 0.59544792 0.59506537 0.59468497 0.5943067  0.59393055\n",
            " 0.5935565  0.59318452 0.59281459 0.5924467  0.59208082 0.59171694\n",
            " 0.59135504 0.5909951  0.5906371  0.59028102 0.58992685 0.58957456\n",
            " 0.58922415 0.58887559 0.58852886 0.58818396 0.58784085 0.58749953\n",
            " 0.58715998 0.58682219 0.58648613 0.5861518  0.58581917 0.58548824\n",
            " 0.58515898 0.58483138 0.58450543 0.58418111 0.5838584  0.58353731\n",
            " 0.5832178  0.58289986 0.58258349 0.58226867 0.58195538 0.58164361\n",
            " 0.58133335 0.58102458 0.5807173  0.58041149 0.58010713 0.57980422\n",
            " 0.57950274 0.57920268 0.57890403 0.57860678 0.57831091 0.57801642\n",
            " 0.57772329 0.5774315  0.57714106 0.57685195 0.57656415 0.57627766\n",
            " 0.57599246 0.57570855 0.57542592 0.57514455 0.57486443 0.57458556\n",
            " 0.57430792 0.57403151 0.57375631 0.57348232 0.57320952 0.57293791\n",
            " 0.57266748 0.57239821 0.5721301  0.57186314 0.57159732 0.57133263\n",
            " 0.57106907 0.57080661 0.57054527 0.57028502 0.57002586 0.56976778\n",
            " 0.56951077 0.56925483 0.56899994 0.5687461  0.5684933  0.56824154\n",
            " 0.5679908  0.56774107 0.56749236 0.56724465 0.56699793 0.5667522\n",
            " 0.56650745 0.56626368 0.56602087 0.56577902 0.56553812 0.56529817\n",
            " 0.56505916 0.56482108 0.56458392 0.56434769 0.56411236 0.56387795\n",
            " 0.56364443 0.5634118  0.56318007 0.56294921 0.56271923 0.56249012\n",
            " 0.56226187 0.56203448 0.56180794 0.56158225 0.56135739 0.56113337\n",
            " 0.56091018 0.56068781 0.56046625 0.56024551 0.56002558 0.55980645\n",
            " 0.55958811 0.55937057 0.55915381 0.55893783 0.55872262 0.55850819\n",
            " 0.55829452 0.55808161 0.55786945 0.55765805 0.55744739 0.55723748\n",
            " 0.5570283  0.55681985 0.55661213 0.55640513 0.55619885 0.55599328\n",
            " 0.55578842 0.55558427 0.55538082 0.55517806 0.554976   0.55477462\n",
            " 0.55457393 0.55437391 0.55417457 0.5539759  0.5537779  0.55358056\n",
            " 0.55338388 0.55318786 0.55299248 0.55279776 0.55260368 0.55241023\n",
            " 0.55221743 0.55202525 0.55183371 0.55164279 0.55145249 0.55126281\n",
            " 0.55107374 0.55088528 0.55069743 0.55051019 0.55032354 0.5501375\n",
            " 0.54995204 0.54976718 0.5495829  0.54939921 0.5492161  0.54903356\n",
            " 0.5488516  0.54867021 0.54848939 0.54830913 0.54812944 0.5479503\n",
            " 0.54777172 0.54759369 0.54741621 0.54723928 0.54706289 0.54688704\n",
            " 0.54671173 0.54653695 0.54636271 0.546189   0.54601581 0.54584315\n",
            " 0.54567101 0.54549939 0.54532828 0.54515769 0.5449876  0.54481803\n",
            " 0.54464896 0.54448039 0.54431233 0.54414476 0.54397768 0.5438111\n",
            " 0.54364501 0.54347941 0.54331429 0.54314966 0.5429855  0.54282183\n",
            " 0.54265863 0.5424959  0.54233365 0.54217186 0.54201054 0.54184968\n",
            " 0.54168929 0.54152936 0.54136988 0.54121086 0.54105229 0.54089418\n",
            " 0.54073651 0.54057929 0.54042251 0.54026618 0.54011029 0.53995483\n",
            " 0.53979982 0.53964523 0.53949108 0.53933736 0.53918407 0.53903121\n",
            " 0.53887877 0.53872675 0.53857515 0.53842397 0.53827321 0.53812286\n",
            " 0.53797293 0.53782341 0.53767429 0.53752559 0.53737729 0.53722939\n",
            " 0.5370819  0.53693481 0.53678811 0.53664181 0.53649591 0.5363504\n",
            " 0.53620529 0.53606056 0.53591622 0.53577227 0.5356287  0.53548552\n",
            " 0.53534271 0.53520029 0.53505825 0.53491658 0.53477529 0.53463437\n",
            " 0.53449382 0.53435365 0.53421384 0.5340744  0.53393533 0.53379662\n",
            " 0.53365827 0.53352029 0.53338266 0.5332454  0.53310849 0.53297193\n",
            " 0.53283573 0.53269989 0.53256439 0.53242924 0.53229444 0.53215999\n",
            " 0.53202589 0.53189212 0.53175871 0.53162563 0.53149289 0.53136049\n",
            " 0.53122843 0.5310967  0.53096531 0.53083425 0.53070353 0.53057313\n",
            " 0.53044307 0.53031333 0.53018392 0.53005483 0.52992607 0.52979763\n",
            " 0.52966952 0.52954172 0.52941425 0.52928709 0.52916025 0.52903372\n",
            " 0.52890751 0.52878161 0.52865603 0.52853076 0.52840579 0.52828114\n",
            " 0.52815679 0.52803275 0.52790901 0.52778558 0.52766245 0.52753962\n",
            " 0.5274171  0.52729487 0.52717294 0.52705131 0.52692997 0.52680893\n",
            " 0.52668819 0.52656774 0.52644758 0.52632771 0.52620813 0.52608884\n",
            " 0.52596984 0.52585112 0.52573269 0.52561455 0.52549669 0.52537911\n",
            " 0.52526181 0.52514479 0.52502806 0.5249116  0.52479542 0.52467952\n",
            " 0.52456389 0.52444854 0.52433346 0.52421866 0.52410412 0.52398986\n",
            " 0.52387587 0.52376215 0.52364869 0.5235355  0.52342258 0.52330993\n",
            " 0.52319754 0.52308541 0.52297355 0.52286194 0.5227506  0.52263952\n",
            " 0.5225287  0.52241814 0.52230783 0.52219778 0.52208799 0.52197845\n",
            " 0.52186916 0.52176013 0.52165135 0.52154283 0.52143455 0.52132652\n",
            " 0.52121874 0.52111121 0.52100393 0.5208969  0.5207901  0.52068356\n",
            " 0.52057726 0.5204712  0.52036539 0.52025981 0.52015448 0.52004939\n",
            " 0.51994453 0.51983992 0.51973554 0.5196314  0.5195275  0.51942383\n",
            " 0.5193204  0.5192172  0.51911424 0.51901151 0.518909   0.51880674\n",
            " 0.5187047  0.51860289 0.51850131 0.51839995 0.51829883 0.51819793\n",
            " 0.51809726 0.51799681 0.51789659 0.51779659 0.51769681 0.51759726\n",
            " 0.51749793 0.51739882 0.51729993 0.51720126 0.51710281 0.51700458\n",
            " 0.51690656 0.51680876 0.51671118 0.51661382 0.51651667 0.51641973\n",
            " 0.51632301 0.5162265  0.5161302  0.51603412 0.51593824 0.51584258\n",
            " 0.51574713 0.51565188 0.51555685 0.51546202 0.5153674  0.51527299\n",
            " 0.51517878 0.51508478 0.51499098 0.51489739 0.514804   0.51471081\n",
            " 0.51461783 0.51452504 0.51443246 0.51434008 0.5142479  0.51415592\n",
            " 0.51406414 0.51397255 0.51388117 0.51378998 0.51369899 0.51360819\n",
            " 0.51351759 0.51342718 0.51333697 0.51324695 0.51315712 0.51306749\n",
            " 0.51297805 0.5128888  0.51279974 0.51271087 0.51262219 0.5125337\n",
            " 0.5124454  0.51235729 0.51226936 0.51218162 0.51209407 0.5120067\n",
            " 0.51191952 0.51183253 0.51174571 0.51165909 0.51157264 0.51148638\n",
            " 0.5114003  0.5113144  0.51122868 0.51114315 0.51105779 0.51097262\n",
            " 0.51088762 0.5108028  0.51071816 0.5106337  0.51054941 0.5104653\n",
            " 0.51038137 0.51029761 0.51021403 0.51013062 0.51004739 0.50996433\n",
            " 0.50988144 0.50979873 0.50971619 0.50963382 0.50955162 0.50946959\n",
            " 0.50938774 0.50930605 0.50922453 0.50914318 0.509062   0.50898099\n",
            " 0.50890014 0.50881947 0.50873895 0.50865861 0.50857843 0.50849842\n",
            " 0.50841857 0.50833888 0.50825936 0.50818    0.50810081 0.50802178\n",
            " 0.5079429  0.5078642  0.50778565 0.50770726 0.50762904 0.50755097\n",
            " 0.50747306 0.50739532 0.50731773 0.5072403  0.50716303 0.50708591\n",
            " 0.50700895 0.50693215 0.5068555  0.50677901 0.50670268 0.5066265\n",
            " 0.50655047 0.5064746  0.50639888 0.50632332 0.50624791 0.50617265\n",
            " 0.50609754 0.50602258 0.50594778 0.50587312 0.50579862 0.50572427\n",
            " 0.50565006 0.50557601 0.5055021  0.50542834 0.50535473 0.50528127\n",
            " 0.50520796 0.50513479 0.50506177 0.50498889 0.50491616 0.50484358\n",
            " 0.50477114 0.50469884 0.50462669 0.50455468 0.50448282 0.5044111\n",
            " 0.50433952 0.50426809 0.50419679 0.50412564 0.50405463 0.50398376\n",
            " 0.50391303 0.50384244 0.50377199 0.50370168 0.50363151 0.50356148\n",
            " 0.50349159 0.50342183 0.50335221 0.50328273 0.50321339 0.50314418\n",
            " 0.50307511 0.50300617 0.50293737 0.50286871 0.50280017 0.50273178\n",
            " 0.50266352 0.50259539 0.5025274  0.50245953 0.50239181 0.50232421\n",
            " 0.50225675 0.50218941 0.50212221 0.50205514 0.50198821 0.5019214\n",
            " 0.50185472 0.50178817 0.50172175 0.50165546 0.5015893  0.50152327\n",
            " 0.50145736 0.50139159 0.50132594 0.50126042 0.50119502 0.50112975\n",
            " 0.50106461 0.50099959 0.5009347  0.50086994 0.5008053  0.50074078\n",
            " 0.50067639 0.50061212 0.50054798 0.50048396 0.50042006 0.50035629\n",
            " 0.50029264 0.50022911 0.5001657  0.50010242 0.50003925 0.49997621\n",
            " 0.49991329 0.49985048 0.4997878  0.49972524 0.4996628  0.49960047\n",
            " 0.49953827 0.49947618 0.49941422 0.49935237 0.49929063 0.49922902\n",
            " 0.49916752 0.49910614 0.49904488 0.49898373 0.4989227  0.49886179\n",
            " 0.49880099 0.4987403  0.49867973 0.49861928 0.49855894 0.49849871\n",
            " 0.4984386  0.4983786  0.49831872 0.49825894 0.49819928 0.49813974\n",
            " 0.4980803  0.49802098 0.49796177 0.49790267 0.49784368 0.4977848\n",
            " 0.49772603 0.49766737 0.49760883 0.49755039 0.49749206 0.49743384\n",
            " 0.49737573 0.49731773 0.49725984 0.49720206 0.49714438 0.49708681\n",
            " 0.49702935 0.49697199 0.49691475 0.49685761 0.49680057 0.49674365\n",
            " 0.49668682 0.49663011 0.4965735  0.49651699 0.49646059 0.49640429\n",
            " 0.4963481  0.49629201 0.49623603 0.49618015 0.49612437 0.4960687\n",
            " 0.49601313 0.49595766 0.4959023  0.49584703 0.49579187 0.49573681\n",
            " 0.49568186 0.495627   0.49557224 0.49551759 0.49546303 0.49540858\n",
            " 0.49535423 0.49529997 0.49524582 0.49519176 0.49513781 0.49508395\n",
            " 0.49503019 0.49497653 0.49492297 0.49486951 0.49481614 0.49476287\n",
            " 0.4947097  0.49465663 0.49460365 0.49455077 0.49449798 0.4944453\n",
            " 0.4943927  0.49434021 0.49428781 0.4942355  0.49418329 0.49413118\n",
            " 0.49407916 0.49402723 0.4939754  0.49392366 0.49387201 0.49382046\n",
            " 0.49376901 0.49371764 0.49366637 0.49361519 0.4935641  0.49351311\n",
            " 0.49346221 0.4934114  0.49336068 0.49331005 0.49325951 0.49320907\n",
            " 0.49315871 0.49310845 0.49305828 0.49300819 0.4929582  0.4929083\n",
            " 0.49285848 0.49280876 0.49275912 0.49270958 0.49266012 0.49261075\n",
            " 0.49256147 0.49251228 0.49246317 0.49241415 0.49236522 0.49231638\n",
            " 0.49226763 0.49221896 0.49217038 0.49212188 0.49207347 0.49202515\n",
            " 0.49197692 0.49192877 0.4918807  0.49183272 0.49178483 0.49173702\n",
            " 0.49168929 0.49164165 0.4915941  0.49154663 0.49149924 0.49145194\n",
            " 0.49140472 0.49135758 0.49131053 0.49126356 0.49121667 0.49116987\n",
            " 0.49112314 0.49107651 0.49102995 0.49098347 0.49093708 0.49089077\n",
            " 0.49084454 0.49079839 0.49075232 0.49070633 0.49066043 0.4906146\n",
            " 0.49056886 0.49052319 0.49047761 0.4904321  0.49038668 0.49034133\n",
            " 0.49029607 0.49025088 0.49020577 0.49016074 0.49011579 0.49007092\n",
            " 0.49002612 0.4899814  0.48993677 0.48989221 0.48984772 0.48980332\n",
            " 0.48975899 0.48971474 0.48967056 0.48962646 0.48958244 0.4895385\n",
            " 0.48949463 0.48945084 0.48940712 0.48936348 0.48931991 0.48927642\n",
            " 0.48923301 0.48918967 0.4891464  0.48910321 0.4890601  0.48901706\n",
            " 0.48897409 0.4889312  0.48888838 0.48884563 0.48880296 0.48876036\n",
            " 0.48871784 0.48867539 0.48863301 0.4885907 ]\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "# Train the model\n",
        "theta_optimal, cost_history = gradient_descent(X_train, y_train, theta, learning_rate, num_iterations)\n",
        "\n",
        "print(\"Optimal parameters:\", theta_optimal)\n",
        "print(\"Cost history over iterations:\", cost_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tooLcJEDueU3",
        "outputId": "c67dbd11-d04e-4015-bece-21714b996f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7932960893854749\n",
            "Confusion Matrix:\n",
            " [[93 12]\n",
            " [25 49]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.83       105\n",
            "           1       0.80      0.66      0.73        74\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.80      0.77      0.78       179\n",
            "weighted avg       0.79      0.79      0.79       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Predict function\n",
        "def predict(X, theta):\n",
        "    probabilities = sigmoid(X.dot(theta))\n",
        "    return probabilities >= 0.5\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = predict(X_test, theta_optimal)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
