{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d-YM2ZFHvI7o",
        "outputId": "f8c1e978-2364-4bcb-ed4f-406c14669dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                  5.1               3.5                1.4               0.2   \n",
              "1                  4.9               3.0                1.4               0.2   \n",
              "2                  4.7               3.2                1.3               0.2   \n",
              "3                  4.6               3.1                1.5               0.2   \n",
              "4                  5.0               3.6                1.4               0.2   \n",
              "..                 ...               ...                ...               ...   \n",
              "145                6.7               3.0                5.2               2.3   \n",
              "146                6.3               2.5                5.0               1.9   \n",
              "147                6.5               3.0                5.2               2.0   \n",
              "148                6.2               3.4                5.4               2.3   \n",
              "149                5.9               3.0                5.1               1.8   \n",
              "\n",
              "     species  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "..       ...  \n",
              "145        2  \n",
              "146        2  \n",
              "147        2  \n",
              "148        2  \n",
              "149        2  \n",
              "\n",
              "[150 rows x 5 columns]>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Load the DataSet\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "iris_df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "iris_df['species'] = y\n",
        "iris_df.tail()\n",
        "iris_df.info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sHvRATo4vkML"
      },
      "outputs": [],
      "source": [
        "# 2. Preprocessing the Data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.47393679  1.20365799 -1.56253475 -1.31260282]\n",
            " [-0.13307079  2.99237573 -1.27600637 -1.04563275]\n",
            " [ 1.08589829  0.08570939  0.38585821  0.28921757]\n",
            " [-1.23014297  0.75647855 -1.2187007  -1.31260282]\n",
            " [-1.7177306   0.30929911 -1.39061772 -1.31260282]\n",
            " [ 0.59831066 -1.25582892  0.72969227  0.95664273]\n",
            " [ 0.72020757  0.30929911  0.44316389  0.4227026 ]\n",
            " [-0.74255534  0.98006827 -1.27600637 -1.31260282]\n",
            " [-0.98634915  1.20365799 -1.33331205 -1.31260282]\n",
            " [-0.74255534  2.32160658 -1.27600637 -1.44608785]\n",
            " [-0.01117388 -0.80864948  0.78699794  0.95664273]\n",
            " [ 0.23261993  0.75647855  0.44316389  0.55618763]\n",
            " [ 1.08589829  0.08570939  0.55777524  0.4227026 ]\n",
            " [-0.49876152  1.87442714 -1.39061772 -1.04563275]\n",
            " [-0.49876152  1.4272477  -1.27600637 -1.31260282]\n",
            " [-0.37686461 -1.47941864 -0.01528151 -0.24472256]\n",
            " [ 0.59831066 -0.58505976  0.78699794  0.4227026 ]\n",
            " [ 0.72020757  0.08570939  1.01622064  0.8231577 ]\n",
            " [ 0.96400139 -0.13788033  0.38585821  0.28921757]\n",
            " [ 1.69538284  1.20365799  1.3600547   1.75755292]\n",
            " [-0.13307079 -0.36147005  0.27124686  0.15573254]\n",
            " [ 2.18297047 -0.13788033  1.64658307  1.22361279]\n",
            " [-0.2549677  -0.13788033  0.44316389  0.4227026 ]\n",
            " [-0.86445224  0.98006827 -1.33331205 -1.31260282]\n",
            " [ 2.30486738 -0.58505976  1.70388875  1.09012776]\n",
            " [-0.01117388 -0.80864948  0.21394119 -0.24472256]\n",
            " [-0.74255534  0.75647855 -1.33331205 -1.31260282]\n",
            " [-0.98634915  0.98006827 -1.39061772 -1.17911778]\n",
            " [-0.86445224  1.65083742 -1.04678367 -1.04563275]\n",
            " [-0.98634915 -2.37377751 -0.12989286 -0.24472256]\n",
            " [ 0.59831066 -0.80864948  0.67238659  0.8231577 ]\n",
            " [-1.23014297  0.75647855 -1.04678367 -1.31260282]\n",
            " [-0.98634915 -0.13788033 -1.2187007  -1.31260282]\n",
            " [-0.86445224  0.53288883 -1.16139502 -0.91214772]\n",
            " [-0.2549677  -0.80864948  0.27124686  0.15573254]\n",
            " [-0.86445224  0.75647855 -1.27600637 -1.31260282]\n",
            " [-0.13307079 -0.13788033  0.27124686  0.02224751]\n",
            " [ 2.30486738  1.65083742  1.70388875  1.35709783]\n",
            " [-1.47393679  0.30929911 -1.33331205 -1.31260282]\n",
            " [ 0.47641375 -0.36147005  0.32855254  0.15573254]\n",
            " [-0.13307079 -1.25582892  0.72969227  1.09012776]\n",
            " [-0.37686461  2.5451963  -1.33331205 -1.31260282]\n",
            " [ 0.23261993 -0.13788033  0.61508092  0.8231577 ]\n",
            " [-0.01117388 -0.80864948  0.78699794  0.95664273]\n",
            " [ 0.23261993 -1.92659808  0.15663551 -0.24472256]\n",
            " [-0.49876152 -0.13788033  0.44316389  0.4227026 ]\n",
            " [ 0.47641375  0.75647855  0.95891497  1.49058286]\n",
            " [-0.37686461 -1.70300836  0.15663551  0.15573254]\n",
            " [-0.49876152  1.87442714 -1.16139502 -1.04563275]\n",
            " [-0.98634915 -1.70300836 -0.24450422 -0.24472256]\n",
            " [ 0.72020757 -0.80864948  0.90160929  0.95664273]\n",
            " [-0.98634915  0.53288883 -1.33331205 -1.31260282]\n",
            " [-0.98634915  0.30929911 -1.4479234  -1.31260282]\n",
            " [-0.37686461 -1.47941864  0.04202416 -0.11123753]\n",
            " [ 1.08589829 -0.13788033  0.72969227  0.68967267]\n",
            " [-1.10824606  0.08570939 -1.27600637 -1.31260282]\n",
            " [-0.01117388 -0.58505976  0.78699794  1.62406789]\n",
            " [-0.98634915  0.75647855 -1.27600637 -1.31260282]\n",
            " [-0.98634915  0.98006827 -1.2187007  -0.77866269]\n",
            " [ 0.11072303  0.30929911  0.61508092  0.8231577 ]\n",
            " [-0.86445224 -1.25582892 -0.41642124 -0.11123753]\n",
            " [ 1.32969211  0.30929911  1.130832    1.49058286]\n",
            " [ 0.23261993 -0.80864948  0.78699794  0.55618763]\n",
            " [ 0.35451684 -1.0322392   1.07352632  0.28921757]\n",
            " [ 2.30486738 -0.13788033  1.3600547   1.49058286]\n",
            " [-0.37686461 -1.25582892  0.15663551  0.15573254]\n",
            " [-1.7177306  -0.36147005 -1.33331205 -1.31260282]\n",
            " [-1.83962751 -0.13788033 -1.50522907 -1.44608785]\n",
            " [ 0.23261993 -1.92659808  0.72969227  0.4227026 ]\n",
            " [ 1.69538284  0.30929911  1.30274902  0.8231577 ]\n",
            " [-1.47393679  0.08570939 -1.27600637 -1.31260282]\n",
            " [-0.86445224  0.98006827 -1.33331205 -1.17911778]\n",
            " [-1.7177306  -0.13788033 -1.39061772 -1.31260282]\n",
            " [ 0.59831066 -1.25582892  0.67238659  0.4227026 ]\n",
            " [ 0.59831066  0.75647855  1.07352632  1.62406789]\n",
            " [-1.47393679  0.75647855 -1.33331205 -1.17911778]\n",
            " [ 1.2077952  -0.13788033  1.01622064  1.22361279]\n",
            " [ 0.59831066  0.53288883  1.30274902  1.75755292]\n",
            " [-1.35203988  0.30929911 -1.39061772 -1.31260282]\n",
            " [ 0.35451684 -0.36147005  0.55777524  0.28921757]\n",
            " [ 0.84210448 -0.58505976  0.50046957  0.4227026 ]\n",
            " [ 0.47641375 -0.58505976  0.61508092  0.8231577 ]\n",
            " [ 1.45158902  0.30929911  0.55777524  0.28921757]\n",
            " [ 0.72020757  0.30929911  0.90160929  1.49058286]\n",
            " [-0.86445224  1.65083742 -1.2187007  -1.31260282]\n",
            " [ 1.32969211  0.08570939  0.95891497  1.22361279]\n",
            " [ 0.11072303 -0.13788033  0.27124686  0.4227026 ]\n",
            " [ 0.84210448 -0.13788033  0.84430362  1.09012776]\n",
            " [-0.13307079 -1.0322392  -0.12989286 -0.24472256]\n",
            " [-0.74255534 -0.80864948  0.09932984  0.28921757]\n",
            " [ 0.35451684 -0.13788033  0.50046957  0.28921757]\n",
            " [-1.5958337  -1.70300836 -1.39061772 -1.17911778]\n",
            " [ 0.96400139 -0.36147005  0.50046957  0.15573254]\n",
            " [-0.37686461 -1.0322392   0.38585821  0.02224751]\n",
            " [-0.62065843  1.4272477  -1.27600637 -1.31260282]\n",
            " [-0.2549677  -0.13788033  0.21394119  0.15573254]\n",
            " [ 1.81727975 -0.36147005  1.47466605  0.8231577 ]\n",
            " [ 1.08589829  0.53288883  1.130832    1.22361279]\n",
            " [-0.86445224  1.4272477  -1.27600637 -1.04563275]\n",
            " [-1.10824606 -1.47941864 -0.24450422 -0.24472256]\n",
            " [ 1.08589829  0.53288883  1.130832    1.75755292]\n",
            " [ 1.69538284 -0.13788033  1.18813767  0.55618763]\n",
            " [-1.10824606  1.20365799 -1.33331205 -1.44608785]\n",
            " [ 1.08589829  0.08570939  1.07352632  1.62406789]\n",
            " [-1.10824606 -0.13788033 -1.33331205 -1.31260282]\n",
            " [ 1.32969211  0.08570939  0.67238659  0.4227026 ]\n",
            " [ 1.93917666 -0.58505976  1.3600547   0.95664273]\n",
            " [ 0.59831066 -0.36147005  1.07352632  0.8231577 ]\n",
            " [-0.13307079 -0.58505976  0.21394119  0.15573254]\n",
            " [ 0.84210448 -0.13788033  1.01622064  0.8231577 ]\n",
            " [ 0.59831066 -1.70300836  0.38585821  0.15573254]\n",
            " [ 0.72020757 -0.36147005  0.32855254  0.15573254]\n",
            " [-0.2549677  -0.58505976  0.67238659  1.09012776]\n",
            " [ 0.11072303 -0.13788033  0.78699794  0.8231577 ]\n",
            " [-0.49876152  0.75647855 -1.16139502 -1.31260282]\n",
            " [ 0.35451684 -0.58505976  0.15663551  0.15573254]\n",
            " [-1.10824606 -1.25582892  0.44316389  0.68967267]\n",
            " [-0.01117388  2.09801686 -1.4479234  -1.31260282]\n",
            " [-0.01117388 -1.0322392   0.15663551  0.02224751]\n",
            " [ 1.57348593 -0.13788033  1.24544335  1.22361279]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7hGohEygvtzN"
      },
      "outputs": [],
      "source": [
        "# 3. Define the Hypothesis (Model)  l\n",
        "# logistic regression model for multi-class classification.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Add intercept term to X\n",
        "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "# Initialize parameters\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = len(np.unique(y_train))\n",
        "theta = np.zeros((n_classes, n_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "3\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(n_features)\n",
        "print(n_classes)\n",
        "print(theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "leo4fAT_v_We"
      },
      "outputs": [],
      "source": [
        "# 4. Define the Cost Function\n",
        "# use the cross-entropy loss function for multi-class classification.\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / exp_z.sum(axis=1, keepdims=True)\n",
        "\n",
        "def compute_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = softmax(X.dot(theta.T))\n",
        "    epsilon = 1e-5  # Small constant to prevent division by zero\n",
        "    y_one_hot = np.eye(n_classes)[y]\n",
        "    cost = -1/m * np.sum(y_one_hot * np.log(h + epsilon))\n",
        "    return cost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function sigmoid at 0x000001D5C45D6980>\n"
          ]
        }
      ],
      "source": [
        "print(sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ILXe0LeJwNYh"
      },
      "outputs": [],
      "source": [
        "# 5. Implement the Optimizer\n",
        "# Gradient Descent to minimize the cost function.\n",
        "\n",
        "def gradient_descent(X, y, theta, learning_rate, num_iterations):\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(num_iterations)\n",
        "    y_one_hot = np.eye(n_classes)[y]\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        h = softmax(X.dot(theta.T))\n",
        "        gradients = -1/m * (y_one_hot - h).T.dot(X)\n",
        "        theta = theta - learning_rate * gradients\n",
        "        cost_history[i] = compute_cost(X, y, theta)\n",
        "\n",
        "    return theta, cost_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYfEdc53wWQp",
        "outputId": "27c429f7-4b89-4342-b9e8-ba6f28b2794e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal parameters: [[-0.23377331 -0.56429005  0.65882701 -0.85948687 -0.80544139]\n",
            " [ 0.47556263  0.14255275 -0.59934182  0.12501013 -0.11515537]\n",
            " [-0.24178932  0.4217373  -0.05948519  0.73447675  0.92059676]]\n",
            "Cost history over iterations: [1.08913578 1.07986424 1.07076465 1.06183397 1.05306921 1.04446737\n",
            " 1.03602547 1.02774056 1.01960971 1.01163001 1.00379858 0.99611257\n",
            " 0.98856915 0.98116554 0.97389897 0.96676672 0.95976609 0.95289444\n",
            " 0.94614913 0.9395276  0.9330273  0.92664573 0.92038041 0.91422894\n",
            " 0.90818892 0.90225801 0.89643391 0.89071435 0.88509712 0.87958004\n",
            " 0.87416096 0.8688378  0.86360848 0.858471   0.85342338 0.84846368\n",
            " 0.84359    0.83880049 0.83409333 0.82946673 0.82491895 0.82044829\n",
            " 0.81605308 0.81173168 0.80748251 0.80330399 0.7991946  0.79515286\n",
            " 0.7911773  0.7872665  0.78341906 0.77963362 0.77590886 0.77224348\n",
            " 0.7686362  0.76508578 0.76159103 0.75815074 0.75476378 0.75142901\n",
            " 0.74814533 0.74491167 0.74172697 0.73859022 0.7355004  0.73245655\n",
            " 0.72945771 0.72650295 0.72359136 0.72072205 0.71789416 0.71510684\n",
            " 0.71235926 0.70965062 0.70698012 0.70434701 0.70175054 0.69918996\n",
            " 0.69666456 0.69417365 0.69171654 0.68929257 0.68690109 0.68454145\n",
            " 0.68221305 0.67991527 0.67764753 0.67540924 0.67319984 0.67101879\n",
            " 0.66886553 0.66673955 0.66464033 0.66256737 0.66052018 0.65849828\n",
            " 0.6565012  0.65452849 0.65257968 0.65065436 0.64875209 0.64687245\n",
            " 0.64501504 0.64317945 0.6413653  0.6395722  0.63779978 0.63604767\n",
            " 0.63431553 0.63260299 0.63090973 0.6292354  0.62757967 0.62594224\n",
            " 0.62432278 0.62272099 0.62113657 0.61956923 0.61801868 0.61648465\n",
            " 0.61496685 0.61346501 0.61197889 0.6105082  0.60905272 0.60761218\n",
            " 0.60618635 0.60477499 0.60337787 0.60199476 0.60062544 0.59926969\n",
            " 0.5979273  0.59659805 0.59528175 0.59397819 0.59268718 0.59140852\n",
            " 0.59014203 0.58888751 0.58764479 0.5864137  0.58519404 0.58398566\n",
            " 0.58278839 0.58160206 0.58042651 0.57926159 0.57810713 0.57696299\n",
            " 0.57582901 0.57470505 0.57359097 0.57248663 0.57139188 0.57030659\n",
            " 0.56923063 0.56816387 0.56710617 0.56605742 0.56501749 0.56398625\n",
            " 0.5629636  0.5619494  0.56094356 0.55994594 0.55895645 0.55797498\n",
            " 0.55700141 0.55603564 0.55507758 0.55412711 0.55318414 0.55224857\n",
            " 0.55132031 0.55039925 0.54948532 0.54857841 0.54767843 0.54678531\n",
            " 0.54589894 0.54501926 0.54414617 0.54327958 0.54241943 0.54156563\n",
            " 0.5407181  0.53987676 0.53904155 0.53821237 0.53738918 0.53657188\n",
            " 0.53576041 0.53495469 0.53415467 0.53336028 0.53257144 0.53178809\n",
            " 0.53101016 0.53023761 0.52947035 0.52870833 0.5279515  0.52719978\n",
            " 0.52645313 0.52571148 0.52497478 0.52424297 0.523516   0.52279381\n",
            " 0.52207636 0.52136357 0.52065542 0.51995184 0.51925278 0.5185582\n",
            " 0.51786805 0.51718227 0.51650083 0.51582367 0.51515075 0.51448202\n",
            " 0.51381745 0.51315698 0.51250057 0.51184818 0.51119977 0.51055529\n",
            " 0.50991471 0.50927798 0.50864508 0.50801594 0.50739055 0.50676885\n",
            " 0.50615082 0.50553641 0.50492559 0.50431833 0.50371458 0.50311431\n",
            " 0.50251749 0.50192409 0.50133407 0.50074739 0.50016403 0.49958395\n",
            " 0.49900712 0.49843352 0.4978631  0.49729583 0.4967317  0.49617066\n",
            " 0.49561269 0.49505777 0.49450585 0.49395691 0.49341093 0.49286788\n",
            " 0.49232773 0.49179045 0.49125602 0.49072441 0.4901956  0.48966955\n",
            " 0.48914625 0.48862567 0.48810778 0.48759257 0.48708    0.48657006\n",
            " 0.48606271 0.48555795 0.48505573 0.48455605 0.48405888 0.4835642\n",
            " 0.48307198 0.48258221 0.48209486 0.48160991 0.48112735 0.48064714\n",
            " 0.48016928 0.47969374 0.4792205  0.47874955 0.47828085 0.47781441\n",
            " 0.47735018 0.47688816 0.47642834 0.47597068 0.47551517 0.4750618\n",
            " 0.47461054 0.47416139 0.47371432 0.47326931 0.47282635 0.47238542\n",
            " 0.47194651 0.4715096  0.47107468 0.47064172 0.47021071 0.46978164\n",
            " 0.46935449 0.46892925 0.4685059  0.46808442 0.46766481 0.46724705\n",
            " 0.46683111 0.466417   0.46600469 0.46559417 0.46518543 0.46477845\n",
            " 0.46437323 0.46396973 0.46356797 0.46316791 0.46276955 0.46237288\n",
            " 0.46197787 0.46158453 0.46119284 0.46080278 0.46041434 0.46002751\n",
            " 0.45964228 0.45925864 0.45887658 0.45849608 0.45811713 0.45773973\n",
            " 0.45736385 0.4569895  0.45661665 0.4562453  0.45587544 0.45550705\n",
            " 0.45514013 0.45477467 0.45441065 0.45404806 0.4536869  0.45332715\n",
            " 0.45296881 0.45261187 0.4522563  0.45190212 0.4515493  0.45119784\n",
            " 0.45084772 0.45049894 0.45015149 0.44980536 0.44946054 0.44911703\n",
            " 0.4487748  0.44843386 0.4480942  0.4477558  0.44741866 0.44708277\n",
            " 0.44674812 0.44641471 0.44608252 0.44575155 0.44542179 0.44509322\n",
            " 0.44476585 0.44443967 0.44411466 0.44379083 0.44346815 0.44314663\n",
            " 0.44282626 0.44250703 0.44218892 0.44187195 0.44155609 0.44124134\n",
            " 0.4409277  0.44061515 0.44030369 0.43999332 0.43968402 0.43937579\n",
            " 0.43906862 0.43876251 0.43845744 0.43815342 0.43785043 0.43754848\n",
            " 0.43724754 0.43694763 0.43664872 0.43635082 0.43605391 0.435758\n",
            " 0.43546308 0.43516913 0.43487616 0.43458415 0.43429311 0.43400302\n",
            " 0.43371388 0.43342569 0.43313844 0.43285212 0.43256673 0.43228226\n",
            " 0.43199871 0.43171606 0.43143433 0.43115349 0.43087355 0.4305945\n",
            " 0.43031634 0.43003905 0.42976264 0.4294871  0.42921242 0.4289386\n",
            " 0.42866563 0.42839352 0.42812225 0.42785181 0.42758222 0.42731345\n",
            " 0.4270455  0.42677838 0.42651207 0.42624658 0.42598189 0.425718\n",
            " 0.42545491 0.42519261 0.4249311  0.42467038 0.42441043 0.42415126\n",
            " 0.42389286 0.42363523 0.42337835 0.42312224 0.42286688 0.42261227\n",
            " 0.42235841 0.42210528 0.4218529  0.42160124 0.42135032 0.42110012\n",
            " 0.42085064 0.42060188 0.42035384 0.4201065  0.41985987 0.41961394\n",
            " 0.41936871 0.41912418 0.41888033 0.41863717 0.4183947  0.4181529\n",
            " 0.41791178 0.41767133 0.41743156 0.41719244 0.41695399 0.4167162\n",
            " 0.41647906 0.41624258 0.41600674 0.41577155 0.41553699 0.41530308\n",
            " 0.4150698  0.41483715 0.41460513 0.41437374 0.41414296 0.41391281\n",
            " 0.41368327 0.41345434 0.41322602 0.41299831 0.4127712  0.41254469\n",
            " 0.41231878 0.41209346 0.41186873 0.41164458 0.41142103 0.41119805\n",
            " 0.41097565 0.41075383 0.41053258 0.41031191 0.4100918  0.40987225\n",
            " 0.40965326 0.40943484 0.40921697 0.40899965 0.40878289 0.40856667\n",
            " 0.408351   0.40813587 0.40792128 0.40770722 0.4074937  0.40728072\n",
            " 0.40706826 0.40685633 0.40664493 0.40643404 0.40622368 0.40601383\n",
            " 0.40580449 0.40559567 0.40538736 0.40517955 0.40497225 0.40476545\n",
            " 0.40455915 0.40435335 0.40414804 0.40394323 0.40373891 0.40353507\n",
            " 0.40333172 0.40312885 0.40292646 0.40272456 0.40252313 0.40232217\n",
            " 0.40212168 0.40192167 0.40172212 0.40152304 0.40132442 0.40112627\n",
            " 0.40092857 0.40073133 0.40053455 0.40033821 0.40014233 0.3999469\n",
            " 0.39975191 0.39955737 0.39936327 0.39916962 0.3989764  0.39878361\n",
            " 0.39859127 0.39839935 0.39820787 0.39801681 0.39782618 0.39763598\n",
            " 0.3974462  0.39725684 0.3970679  0.39687937 0.39669127 0.39650357\n",
            " 0.39631629 0.39612942 0.39594296 0.3957569  0.39557125 0.395386\n",
            " 0.39520115 0.3950167  0.39483265 0.394649   0.39446573 0.39428287\n",
            " 0.39410039 0.3939183  0.3937366  0.39355528 0.39337435 0.3931938\n",
            " 0.39301363 0.39283384 0.39265443 0.3924754  0.39229673 0.39211845\n",
            " 0.39194053 0.39176298 0.3915858  0.39140898 0.39123253 0.39105645\n",
            " 0.39088072 0.39070536 0.39053035 0.3903557  0.39018141 0.39000747\n",
            " 0.38983389 0.38966065 0.38948777 0.38931523 0.38914304 0.3889712\n",
            " 0.3887997  0.38862854 0.38845772 0.38828725 0.38811711 0.38794731\n",
            " 0.38777784 0.38760871 0.38743991 0.38727145 0.38710331 0.3869355\n",
            " 0.38676802 0.38660087 0.38643404 0.38626753 0.38610135 0.38593548\n",
            " 0.38576994 0.38560471 0.38543981 0.38527521 0.38511094 0.38494697\n",
            " 0.38478332 0.38461998 0.38445695 0.38429422 0.38413181 0.3839697\n",
            " 0.38380789 0.38364639 0.38348519 0.38332429 0.38316369 0.38300339\n",
            " 0.38284339 0.38268368 0.38252427 0.38236515 0.38220633 0.38204779\n",
            " 0.38188955 0.3817316  0.38157394 0.38141656 0.38125947 0.38110266\n",
            " 0.38094614 0.3807899  0.38063395 0.38047827 0.38032288 0.38016776\n",
            " 0.38001292 0.37985835 0.37970407 0.37955005 0.37939631 0.37924285\n",
            " 0.37908965 0.37893672 0.37878407 0.37863168 0.37847956 0.3783277\n",
            " 0.37817611 0.37802479 0.37787372 0.37772292 0.37757238 0.37742211\n",
            " 0.37727209 0.37712233 0.37697282 0.37682358 0.37667459 0.37652585\n",
            " 0.37637737 0.37622914 0.37608116 0.37593343 0.37578596 0.37563873\n",
            " 0.37549175 0.37534502 0.37519853 0.37505229 0.3749063  0.37476054\n",
            " 0.37461503 0.37446977 0.37432474 0.37417995 0.37403541 0.3738911\n",
            " 0.37374703 0.3736032  0.3734596  0.37331624 0.37317311 0.37303021\n",
            " 0.37288755 0.37274512 0.37260292 0.37246095 0.37231921 0.3721777\n",
            " 0.37203642 0.37189536 0.37175453 0.37161393 0.37147355 0.37133339\n",
            " 0.37119346 0.37105375 0.37091426 0.37077499 0.37063594 0.37049711\n",
            " 0.3703585  0.37022011 0.37008193 0.36994397 0.36980622 0.36966869\n",
            " 0.36953138 0.36939427 0.36925738 0.3691207  0.36898424 0.36884798\n",
            " 0.36871193 0.36857609 0.36844046 0.36830504 0.36816982 0.36803481\n",
            " 0.36790001 0.36776541 0.36763101 0.36749682 0.36736283 0.36722904\n",
            " 0.36709545 0.36696207 0.36682888 0.3666959  0.36656311 0.36643052\n",
            " 0.36629812 0.36616593 0.36603393 0.36590212 0.36577052 0.3656391\n",
            " 0.36550788 0.36537685 0.36524601 0.36511537 0.36498491 0.36485465\n",
            " 0.36472457 0.36459469 0.36446499 0.36433548 0.36420616 0.36407703\n",
            " 0.36394808 0.36381932 0.36369074 0.36356234 0.36343413 0.36330611\n",
            " 0.36317826 0.3630506  0.36292312 0.36279582 0.3626687  0.36254176\n",
            " 0.362415   0.36228841 0.36216201 0.36203578 0.36190973 0.36178386\n",
            " 0.36165816 0.36153263 0.36140728 0.36128211 0.36115711 0.36103228\n",
            " 0.36090762 0.36078314 0.36065883 0.36053469 0.36041072 0.36028691\n",
            " 0.36016328 0.36003982 0.35991652 0.3597934  0.35967044 0.35954764\n",
            " 0.35942501 0.35930255 0.35918026 0.35905812 0.35893616 0.35881435\n",
            " 0.35869271 0.35857123 0.35844992 0.35832876 0.35820777 0.35808694\n",
            " 0.35796627 0.35784575 0.3577254  0.35760521 0.35748517 0.35736529\n",
            " 0.35724557 0.35712601 0.3570066  0.35688735 0.35676825 0.35664931\n",
            " 0.35653053 0.3564119  0.35629342 0.35617509 0.35605692 0.3559389\n",
            " 0.35582103 0.35570332 0.35558575 0.35546833 0.35535107 0.35523395\n",
            " 0.35511699 0.35500017 0.3548835  0.35476698 0.35465061 0.35453438\n",
            " 0.3544183  0.35430237 0.35418658 0.35407094 0.35395544 0.35384009\n",
            " 0.35372488 0.35360982 0.3534949  0.35338012 0.35326548 0.35315099\n",
            " 0.35303664 0.35292243 0.35280836 0.35269443 0.35258064 0.35246699\n",
            " 0.35235348 0.35224011 0.35212688 0.35201378 0.35190082 0.35178801\n",
            " 0.35167532 0.35156278 0.35145037 0.3513381  0.35122596 0.35111395\n",
            " 0.35100209 0.35089035 0.35077875 0.35066729 0.35055596 0.35044476\n",
            " 0.35033369 0.35022275 0.35011195 0.35000128 0.34989074 0.34978033\n",
            " 0.34967005 0.3495599  0.34944988 0.34933999 0.34923023 0.34912059\n",
            " 0.34901109 0.34890171 0.34879246 0.34868334 0.34857435 0.34846548\n",
            " 0.34835674 0.34824812 0.34813963 0.34803126 0.34792302 0.34781491\n",
            " 0.34770691 0.34759905 0.3474913  0.34738368 0.34727618 0.34716881\n",
            " 0.34706155 0.34695442 0.34684741 0.34674052 0.34663376 0.34652711\n",
            " 0.34642058 0.34631418 0.34620789 0.34610172 0.34599567 0.34588974\n",
            " 0.34578393 0.34567824 0.34557267 0.34546721 0.34536187 0.34525664\n",
            " 0.34515154 0.34504655 0.34494167 0.34483692 0.34473227 0.34462775\n",
            " 0.34452333 0.34441904 0.34431485 0.34421078 0.34410683 0.34400298\n",
            " 0.34389925 0.34379564 0.34369213 0.34358874 0.34348546 0.34338229\n",
            " 0.34327924 0.34317629 0.34307346 0.34297074 0.34286812 0.34276562\n",
            " 0.34266323 0.34256094 0.34245877 0.3423567  0.34225474 0.3421529\n",
            " 0.34205116 0.34194952 0.341848   0.34174658 0.34164527 0.34154407\n",
            " 0.34144297 0.34134198 0.3412411  0.34114032 0.34103965 0.34093908\n",
            " 0.34083862 0.34073826 0.340638   0.34053786 0.34043781 0.34033787\n",
            " 0.34023803 0.3401383  0.34003867 0.33993914 0.33983971 0.33974039\n",
            " 0.33964117 0.33954205 0.33944303 0.33934411]\n"
          ]
        }
      ],
      "source": [
        "# 6. Train the Model\n",
        "\n",
        "# Define hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "\n",
        "# Train the model\n",
        "theta_optimal, cost_history = gradient_descent(X_train, y_train, theta, learning_rate, num_iterations)\n",
        "\n",
        "print(\"Optimal parameters:\", theta_optimal)\n",
        "print(\"Cost history over iterations:\", cost_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1IuV5ylwjlU",
        "outputId": "e094ebce-6a0b-4401-a157-4900b3c966c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "Confusion Matrix:\n",
            " [[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Evaluate the Model\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Predict function\n",
        "def predict(X, theta):\n",
        "    probabilities = softmax(X.dot(theta.T))\n",
        "    return np.argmax(probabilities, axis=1)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = predict(X_test, theta_optimal)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
